{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# occupancy prediction\n",
    "\n",
    "![img](dev/IMG_6435.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plan:\n",
    "- split `real_data_array` into `timeunit` chunks\n",
    "- compute transition matrix for each chunk\n",
    "- simulate `timeunit` length of data using each transition matrix\n",
    "- compare simulated data to each respective real data chunk\n",
    "- make sure to normalize the *`timestep`* with `scipy.signal.decimate`\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# set autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import signal\n",
    "from tqdm import tqdm_notebook, tnrange, trange, tqdm\n",
    "from itertools import cycle\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "import time\n",
    "from contextlib import suppress\n",
    "\n",
    "import altair as alt\n",
    "from altair.expr import datum\n",
    "alt.data_transformers.enable('json')\n",
    "\n",
    "from _modules.wifi_traffic_analyzer import WifiTrafficAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestep = 250\n",
    "timeunit = 10_000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data_path_dict = {\n",
    "    'real_2': Path(r'data/wifitrafficstats2.csv'),\n",
    "    'real_3': Path(r'data/wifitrafficstats3.csv'),\n",
    "    'real_4': Path(r'data/wifitrafficstats4.csv'),\n",
    "    'real_5': Path(r'data/wifitrafficstats5.csv'),\n",
    "    'real_6': Path(r'data/wifitrafficstats6.csv')\n",
    "}\n",
    "\n",
    "transition_matrices_path_dict = {\n",
    "    'tmat_1': Path(r'data/wifi_t_matrices.csv'),\n",
    "    #'tmat_2': Path(r'data/wifi_t_matrices2.csv')\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## occupancy predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classing it up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OccupancyPredictor:\n",
    "    def __init__(self, real_data_path_dict, timeunits, timesteps, autoselect_file=True):\n",
    "        print('initializing OP..')\n",
    "        \n",
    "        # attributes\n",
    "        self.real_data_path_dict = real_data_path_dict\n",
    "        \n",
    "        # set timeunits\n",
    "        if not isinstance(timeunits, list):\n",
    "            self.timeunits = [timeunits]\n",
    "            print(f'single timeunit received {self.timeunits}')\n",
    "        else:\n",
    "            self.timeunits = timeunits\n",
    "            print(f'{len(self.timeunits)} timeunits received')\n",
    "            \n",
    "        # set timesteps\n",
    "        if not isinstance(timesteps, list):\n",
    "            self.timesteps = [timesteps]\n",
    "            print(f'single timestep received {self.timesteps}')\n",
    "        else:\n",
    "            if len(self.timeunits) > 1:\n",
    "                print('ERROR: timeunit already list, timestep must be single value')\n",
    "                raise ValueError\n",
    "            self.timesteps = timesteps\n",
    "            print(f'{len(self.timesteps)} timesteps received')\n",
    "        \n",
    "        # startup tasks\n",
    "        self.WTA_real = WifiTrafficAnalyzer(mode='real', path_dict=self.real_data_path_dict)\n",
    "        self.select_file_key(autoselect=autoselect_file)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def select_file_key(self, autoselect):        \n",
    "        if autoselect:\n",
    "            self.file_key = list(self.WTA_real.path_dict.keys())[1]\n",
    "            self.WTA_real.process_real_data(self.file_key)\n",
    "            print(f'\\tautoselected and processed \\'{self.file_key}\\'')\n",
    "            \n",
    "        else:\n",
    "            file_key = input('please select a target file..')\n",
    "            \n",
    "            try:\n",
    "                assert file_key.strip().lower() in self.WTA_real.path_dict.keys()\n",
    "                \n",
    "                self.file_key = file_key.strip().lower()\n",
    "                self.WTA_real.process_real_data(self.file_key)\n",
    "                \n",
    "                print(f'\\tset and processed target file: {self.file_key}')\n",
    "                \n",
    "            except AssertionError:\n",
    "                print(f'invalid target file: {file_key}, options are {self.WTA_real.path_dict.keys()}')\n",
    "                raise\n",
    "        \n",
    "        \n",
    "    def convert_and_reshape(self, timeunit, downsample_factor):\n",
    "        self.data_array = self.decimate_signal(\n",
    "            self.WTA_real.real_data_array,\n",
    "            downsample_factor\n",
    "        )\n",
    "        print(f'generated real data array, size: {self.data_array.shape}')\n",
    "        \n",
    "        data_matrix = (\n",
    "            self.data_array[\n",
    "                :int(timeunit*np.floor(len(self.data_array) / timeunit))\n",
    "            ].reshape((-1, timeunit))\n",
    "        )\n",
    "        print(f'reshaped into {data_matrix.shape[0]} : {timeunit}µs chunks')\n",
    "        \n",
    "        return data_matrix\n",
    "    \n",
    "    \n",
    "    def decimate_signal(self, data_array, factor):\n",
    "        with suppress(FutureWarning):\n",
    "            return signal.decimate(\n",
    "                tuple(data_array),\n",
    "                factor,\n",
    "                ftype='fir'\n",
    "            )\n",
    "    \n",
    "        \n",
    "    def compute_transition_matrix(self, row, timeunit):\n",
    "        onon, onoff, offon, offoff = 0, 0, 0, 0\n",
    "        \n",
    "        for i in range(timeunit-1):    \n",
    "            # if ON -> ON\n",
    "            if row[i] == row[i+1] == 1:\n",
    "                onon += 1\n",
    "                \n",
    "            # if ON -> OFF\n",
    "            elif row[i] == 1 and row[i+1] == 0:\n",
    "                onoff += 1\n",
    "                \n",
    "            # if OFF -> ON\n",
    "            elif row[i] == 0 and row[i+1] == 1:\n",
    "                offon += 1\n",
    "                \n",
    "            #if OFF -> OFF\n",
    "            elif row[i] == row[i+1] == 0:\n",
    "                offoff += 1\n",
    "                \n",
    "        try:\n",
    "            p_onon = onon / (onon + onoff)\n",
    "        except ZeroDivisionError:\n",
    "            p_onon = 0\n",
    "        \n",
    "        try:\n",
    "            p_offoff = offoff / (offoff + offon)\n",
    "        except ZeroDivisionError:\n",
    "            p_offoff = 0\n",
    "            \n",
    "        try:\n",
    "            p_onoff = onoff / (onon + onoff)\n",
    "        except ZeroDivisionError:\n",
    "            p_onoff = 0\n",
    "            \n",
    "        try:\n",
    "            p_offon = offon / (offoff + offon)\n",
    "        except ZeroDivisionError:\n",
    "            p_offon = 0\n",
    "            \n",
    "        \n",
    "        return (p_onon, p_onoff, p_offon, p_offoff) \n",
    "    \n",
    "    \n",
    "    def compute_tmats_and_load_df(self, data_matrix, timeunit):\n",
    "        # compute all transition matrices\n",
    "        tmat_array = [\n",
    "            self.compute_transition_matrix(\n",
    "                data_matrix[idx,:],\n",
    "                timeunit\n",
    "            )\n",
    "            for idx in tnrange(data_matrix.shape[0])\n",
    "        ]\n",
    "        \n",
    "        # load dataframe\n",
    "        tmat_df = (\n",
    "            pd\n",
    "            .DataFrame(\n",
    "                tmat_array, \n",
    "                columns=['OnOn', 'OnOff', 'OffOn', 'OffOff']\n",
    "            ).assign(\n",
    "                timeunit = timeunit,\n",
    "                source = self.file_key\n",
    "            )\n",
    "            [['OnOn','OnOff','OffOff','OffOn','timeunit','source']]\n",
    "        )\n",
    "        print(f'created transition matrix dataframe, {tmat_df.shape[0]} rows')\n",
    "        \n",
    "        return tmat_df\n",
    "    \n",
    "    \n",
    "    def process_timeunit(self, timeunit, timestep):\n",
    "        print(f'processing data for timeunit: {timeunit}µs')\n",
    "        \n",
    "        data_matrix = self.convert_and_reshape(timeunit, timestep)        \n",
    "        tmat_df = self.compute_tmats_and_load_df(data_matrix, timeunit)\n",
    "        \n",
    "        return data_matrix, tmat_df\n",
    "    \n",
    "        \n",
    "    def iterate_timeunits(self):\n",
    "        df_dict = {}\n",
    "        timestep = self.timesteps[0]\n",
    "        print(f'iterating timeunits, using fixed timestep: {timestep}')\n",
    "        \n",
    "        for timeunit in tqdm_notebook(self.timeunits): \n",
    "            data_matrix, tmat_df = self.process_timeunit(int(timeunit/timestep), timestep) \n",
    "            print(f'data matrix: {data_matrix.shape}')\n",
    "        \n",
    "            sim_data_matrix = self.WTA_real.simulate_all_OP_transition_matrices(\n",
    "                tmat_dataframe=tmat_df,\n",
    "                n_samples=int(timeunit/timestep), \n",
    "                m_trials=1\n",
    "            )[1:,:]\n",
    "            \n",
    "            print(f'sim data matrix: {sim_data_matrix.shape}')\n",
    "            \n",
    "            comp_df = (\n",
    "                pd\n",
    "                .DataFrame({\n",
    "                    'real_data': data_matrix.sum(axis=1),\n",
    "                    'sim_data': sim_data_matrix.sum(axis=1)\n",
    "                })\n",
    "                .assign(\n",
    "                    real_data = lambda x: x.real_data.astype('int'),\n",
    "                    sim_data = lambda x: x.sim_data.astype('int'),\n",
    "                    timestep = timestep,\n",
    "                    timeunit = timeunit\n",
    "                )\n",
    "                .eval('diff = sim_data - real_data')\n",
    "            )\n",
    "            \n",
    "            df_dict[timeunit] = comp_df            \n",
    "        \n",
    "        return pd.concat([df for df in df_dict.values()])\n",
    "    \n",
    "    \n",
    "    def iterate_timesteps(self):\n",
    "        df_dict = {}\n",
    "        timeunit = self.timeunits[0]\n",
    "        print(f'iterating timeunits, using fixed timestep: {timeunit}')\n",
    "        \n",
    "        for timestep in tqdm_notebook(self.timesteps): \n",
    "            data_matrix, tmat_df = self.process_timeunit(int(timeunit/timestep), timestep) \n",
    "            print(f'data matrix: {data_matrix.shape}')\n",
    "        \n",
    "            sim_data_matrix = self.WTA_real.simulate_all_OP_transition_matrices(\n",
    "                tmat_dataframe=tmat_df,\n",
    "                n_samples=int(timeunit/timestep), \n",
    "                m_trials=1\n",
    "            )[1:,:]\n",
    "            \n",
    "            print(f'sim data matrix: {sim_data_matrix.shape}')\n",
    "            \n",
    "            comp_df = (\n",
    "                pd\n",
    "                .DataFrame({\n",
    "                    'real_data': data_matrix.sum(axis=1),\n",
    "                    'sim_data': sim_data_matrix.sum(axis=1)\n",
    "                })\n",
    "                .assign(\n",
    "                    real_data = lambda x: x.real_data.astype('int'),\n",
    "                    sim_data = lambda x: x.sim_data.astype('int'),\n",
    "                    timestep = timestep,\n",
    "                    timeunit = timeunit\n",
    "                )\n",
    "                .eval('diff = sim_data - real_data')\n",
    "            )\n",
    "            \n",
    "            df_dict[timeunit] = comp_df            \n",
    "        \n",
    "        return pd.concat([df for df in df_dict.values()])\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iterating timeunits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing OP..\n",
      "40 timeunits received\n",
      "single timestep received [1000]\n",
      "initializing WTA..\n",
      "initialization complete, mode: real\n",
      "real data options: \n",
      "\tkey: real_2, path: data\\wifitrafficstats2.csv\n",
      "\tkey: real_3, path: data\\wifitrafficstats3.csv\n",
      "\tkey: real_4, path: data\\wifitrafficstats4.csv\n",
      "\tkey: real_5, path: data\\wifitrafficstats5.csv\n",
      "\tkey: real_6, path: data\\wifitrafficstats6.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e56451bc0d32464da82e4138a671d4b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=148455), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tautoselected and processed 'real_3'\n"
     ]
    }
   ],
   "source": [
    "OP = OccupancyPredictor(\n",
    "    real_data_path_dict, \n",
    "    timeunits=list(range(9000, 11000, 50)), \n",
    "    timesteps=1000, \n",
    "    autoselect_file=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterating timeunits, using fixed timestep: 1000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b7b85a1dacb438f9151094133d31f0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=40), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for timeunit: 9µs\n",
      "generated real data array, size: (71885,)\n",
      "reshaped into 7987 : 9µs chunks\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c24290e2a404713844f9f0ffdd22ff0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7987), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created transition matrix dataframe, 7987 rows\n",
      "data matrix: (7987, 9)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "830c6ae5730246458a3c61ebe65d3dd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7987), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total elapsed time: 0.01 minutes\n",
      "sim data matrix: (7987, 9)\n",
      "processing data for timeunit: 9µs\n",
      "generated real data array, size: (71885,)\n",
      "reshaped into 7987 : 9µs chunks\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85d5772d862c477b82b12bc9a8fdc591",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7987), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created transition matrix dataframe, 7987 rows\n",
      "data matrix: (7987, 9)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc72b7d0f80941cead0a7aa0fc01b602",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7987), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total elapsed time: 0.01 minutes\n",
      "sim data matrix: (7987, 9)\n",
      "processing data for timeunit: 9µs\n",
      "generated real data array, size: (71885,)\n",
      "reshaped into 7987 : 9µs chunks\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f672b1beb004505af531a580a15b41c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7987), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created transition matrix dataframe, 7987 rows\n",
      "data matrix: (7987, 9)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dfd866710f54afab2e8f95eb3057e38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7987), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total elapsed time: 0.01 minutes\n",
      "sim data matrix: (7987, 9)\n",
      "processing data for timeunit: 9µs\n",
      "generated real data array, size: (71885,)\n",
      "reshaped into 7987 : 9µs chunks\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cffe30483f14ae7af16ed466a9ce122",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7987), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created transition matrix dataframe, 7987 rows\n",
      "data matrix: (7987, 9)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4222952209ba4806bd766d519d67a1df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7987), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total elapsed time: 0.01 minutes\n",
      "sim data matrix: (7987, 9)\n",
      "processing data for timeunit: 9µs\n",
      "generated real data array, size: (71885,)\n",
      "reshaped into 7987 : 9µs chunks\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b23bf4415db2405eb4180e574ee94aa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7987), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created transition matrix dataframe, 7987 rows\n",
      "data matrix: (7987, 9)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7e50ca476cb47aca37d4130538b422f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7987), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total elapsed time: 0.01 minutes\n",
      "sim data matrix: (7987, 9)\n",
      "processing data for timeunit: 9µs"
     ]
    }
   ],
   "source": [
    "full_comp_df = OP.iterate_timeunits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iterating timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing OP..\n",
      "40 timeunits received\n",
      "single timestep received [1000]\n",
      "initializing WTA..\n",
      "initialization complete, mode: real\n",
      "real data options: \n",
      "\tkey: real_2, path: data\\wifitrafficstats2.csv\n",
      "\tkey: real_3, path: data\\wifitrafficstats3.csv\n",
      "\tkey: real_4, path: data\\wifitrafficstats4.csv\n",
      "\tkey: real_5, path: data\\wifitrafficstats5.csv\n",
      "\tkey: real_6, path: data\\wifitrafficstats6.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e56451bc0d32464da82e4138a671d4b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=148455), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tautoselected and processed 'real_3'\n"
     ]
    }
   ],
   "source": [
    "OP = OccupancyPredictor(\n",
    "    real_data_path_dict, \n",
    "    timeunits=list(range(9000, 11000, 50)), \n",
    "    timesteps=1000, \n",
    "    autoselect_file=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_comp_df = OP.iterate_timesteps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = {}\n",
    "timesteps = list(range(50, 2000, 50))\n",
    "timeunit = 10_000\n",
    "\n",
    "for tstep in timesteps:\n",
    "    df_dict[tstep] = iterate_params(tstep, timeunit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_comp_df = pd.concat([df for df in df_dict.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(full_comp_df\n",
    " .eval('real_data = real_data * timestep / timeunit')\n",
    " .eval('sim_data = sim_data * timestep / timeunit')\n",
    " .assign(pct_diff = lambda x: np.abs(x.sim_data - x.real_data))\n",
    " .head()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_comp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_comp_df.groupby('timestep').diff.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(\n",
    "    full_comp_df\n",
    ").mark_circle(\n",
    ").encode(\n",
    "    alt.X('timestep:N'),\n",
    "    alt.Y('mean(diff):Q')\n",
    ").configure(\n",
    "    background='#abb2bf'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OP = OccupancyPredictor(real_data_path_dict, timeunit, autoselect_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_matrix, tmat_df = OP.process_timeunit(int(OP.timeunits[0]/timestep))\n",
    "\n",
    "print(f'data matrix: {data_matrix.shape}')\n",
    "display(tmat_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_data_matrix = OP.WTA_real.simulate_all_OP_transition_matrices(\n",
    "    tmat_dataframe=tmat_df,\n",
    "    n_samples=int(OP.timeunits[0]/timestep), \n",
    "    m_trials=1\n",
    ")[1:,:]\n",
    "\n",
    "print(f'sim data matrix: {sim_data_matrix.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'real data shape: {data_matrix.shape}')\n",
    "data_matrix.sum(axis=1)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'sim data shape: {sim_data_matrix.shape}')\n",
    "sim_data_matrix.sum(axis=1)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_df = (\n",
    "    pd\n",
    "    .DataFrame({\n",
    "        'real_data': data_matrix.sum(axis=1),\n",
    "        'sim_data': sim_data_matrix.sum(axis=1)\n",
    "    })\n",
    "    .assign(\n",
    "        real_data = lambda x: x.real_data.astype('int'),\n",
    "        sim_data = lambda x: x.sim_data.astype('int')\n",
    "    )\n",
    "    .eval('diff = sim_data - real_data')\n",
    ")\n",
    "\n",
    "comp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scaler = alt.selection_interval(encodings=['x'])\n",
    "\n",
    "base = alt.Chart(\n",
    "    comp_df.reset_index().sample(frac=0.5),\n",
    "    height=200,\n",
    "    width=800\n",
    "#).transform_filter(\n",
    "#    x_scaler\n",
    ").mark_line(\n",
    "    opacity=0.5\n",
    ").encode(\n",
    "    alt.X('index:Q', scale={'domain': x_scaler.ref()}),\n",
    "    #alt.Y('real_data:Q')\n",
    ")\n",
    "\n",
    "layered = alt.vconcat(\n",
    "    base.encode(\n",
    "        alt.Y('real_data:Q'),\n",
    "        color=alt.value('#4286f4') # blue\n",
    "    ).transform_filter(x_scaler),\n",
    "    base.encode(\n",
    "        alt.Y('sim_data:Q'),\n",
    "        color=alt.value('#41f470') # green\n",
    "    ).transform_filter(x_scaler),\n",
    "    base.encode(\n",
    "        alt.Y('diff:Q'),\n",
    "        color=alt.value('#f44141') # red\n",
    "    ).transform_filter(x_scaler),\n",
    ")\n",
    "\n",
    "wide = base.encode(alt.Y('diff:Q')).add_selection(x_scaler).properties(height=100)\n",
    "\n",
    "alt.vconcat(layered, wide, background='#abb2bf')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## misfits"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tmat_df.loc[\n",
    "    lambda x: [\n",
    "        True \n",
    "            if onon == 0 and onoff == 0 \n",
    "            else False \n",
    "        for onon, onoff in zip(x.onon, x.onoff)\n",
    "    ]\n",
    "].shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tmat_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
